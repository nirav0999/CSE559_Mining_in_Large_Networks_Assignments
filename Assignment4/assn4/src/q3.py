# -*- coding: utf-8 -*-
"""MLN_Q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A5mVs3fjYTxDNlGp4p69XokiScV2-U0l

# Install Libraries
"""

# !pip install dgl

"""# Imports"""

import dgl
import dgl.function as fn
import torch as th
import torch.nn as nn
import torch.nn.functional as F
from dgl import DGLGraph
from dgl.data import citation_graph as citegrh
import networkx as nx
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import time
import numpy as np

"""# MODEL"""

class GCNLayer(nn.Module):
    def __init__(self, in_feats, out_feats):
        # Inheriting the class layer
        super(GCNLayer, self).__init__()
        # Declaring the Linear Layer
        self.linear = nn.Linear(in_feats, out_feats)

    def message_func(self,edges):
        #New Edges are the messages functions
        new_edges = None

        #Iterating the edges
        for i_no,row in enumerate(edges.src['h']):
            
            #Source Vertex
            src = edges.edges()[0][i_no]
            #Degree of Source Vertex
            degree_src = degrees[src]
            #Dividing by root of degree
            new_row = row/(degree_src ** (1/2))
            
            #making the tensor
            if i_no == 0:
                new_edges = new_row
            elif i_no == 1:
                new_edges = th.stack((new_edges,new_row),0)
            else:
                #Stacking the tensors one over the other
                new_row = new_row.unsqueeze(1)
                new_row = th.transpose(new_row, 0, 1)
                new_edges = th.cat((new_edges,new_row),dim = 0)
        
        return {'m': new_edges}

    def reduce_func(self,nodes):
        #Get the sum of messages from each neighbor 
        h = th.sum(nodes.mailbox['m'], dim = 1)
        new_h = None
        
        #Enumerate the nodes
        for i_no,node in enumerate(nodes.nodes()):

            #Normalize by square root of degree
            new_row =  h[i_no]/(degrees[node]**(1/2))
            
            if i_no == 0:

                #Initializing for the first node
                new_row = new_row.unsqueeze(1)
                new_row = th.transpose(new_row, 0, 1)
                new_h = new_row
            
            else:

                #Stacking up the tensors
                new_row = new_row.unsqueeze(1)
                new_row = th.transpose(new_row, 0, 1)
                new_h = th.cat((new_h,new_row),dim = 0)
        return {'h': new_h}

    def forward(self, g, feature):
        #Creating a local Scope
        with g.local_scope():
            #Assigning the feature data
            g.ndata['h'] = feature
            #Passing messages and
            #Collecting the messages and applying reduce function  
            g.update_all(self.message_func, self.reduce_func)
            h = g.ndata['h']
            #Passing it through FC layer
            return self.linear(h)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        #Declaring FC GCNLayers 
        self.layer1 = GCNLayer(34, 32)
        self.layer2 = GCNLayer(32, 2)

    def forward(self, g, features):
        # Passing through first FC Layer 
        x = self.layer1(g, features)
        #Relu Activation Function
        x = F.relu(x)
        #Second Activation Function
        x = self.layer2(g, x)
        return x

"""# LOAD GRAPH"""

#Load Karate Club Graph in Networkx
nx_karate_graph = nx.karate_club_graph()

#Load the networkx object into dgl graph object
dgl_karate_graph = dgl.DGLGraph(nx_karate_graph)

#print the karate gnx_karate_graphraph object  to get basic graph info
print(dgl_karate_graph)

"""#Initialize and Make Features"""

def make_one_hot_encoded_vector(n = 34):
    """
    Makes a n X n 0's numpy array with diagonals filled with 1's
    """
    arr = np.zeros((n,n))
    for i in range(n):
        arr[i,i] = 1
    print(arr)
    return arr.astype(float)

def make_train_test_masks(n,train_set):
    """
    Making Train and Test Masks
    """
    test_mask = [True] * n
    train_mask = [False] * n
    for index in train_set:
        train_mask[index] = True
        test_mask[index] = False
    return np.array(train_mask),np.array(test_mask)

def make_labels_for_zachary_graph(graph):
    """
    Assign the nodes labels for semi-supervised learning
    """
    #Labels initialize with all zeros
    labels = np.zeros(len(list(graph.nodes())))

    #Community names in the graph
    communities = {"Mr. Hi" : 0,"Officer" : 1}

    #Assigning th labels
    for i in graph.nodes():
        community_name = graph.nodes[i]['club']
        labels[i] = communities[community_name]
    return labels

#Making the one-hot encoded Features
one_hot_encoded_vector = make_one_hot_encoded_vector(n = 34)

#Converting it into Tensor
features = th.from_numpy(one_hot_encoded_vector).float()
print("Features Tensor = ",features)
print("Shape of Features Tensor = ",features.shape)

#Making the labels for the Zachary Graph
#communities = {"Mr. Hi" : 0,"Officer" : 1}
zachary_labels = make_labels_for_zachary_graph(nx_karate_graph)

#Converting it into Tensor
labels = th.from_numpy(zachary_labels).long()
print("Labels Tensor = ",labels)
print("Shape of Labels Tensor = ",labels.shape)

#Make Train mask and Test Mask 
Train_Set_Labels = [0,33]
train_mask_arr,test_mask_arr = make_train_test_masks(34,Train_Set_Labels)

#Converting it into Tensor
train_mask = th.from_numpy(train_mask_arr)
print("train_mask Tensor = ",train_mask)
print("Shape of train_mask Tensor = ",train_mask.shape)

#Converting it into Tensor
test_mask = th.from_numpy(test_mask_arr)
print("test_mask Tensor = ",test_mask)
print("Shape of test_mask Tensor = ",test_mask.shape)


print(features.shape)
print(labels.shape)
print(train_mask.shape)
print(test_mask.shape)

def visualize_features(logits,labels,title):
    """
    Visualize the features
    """
    fig, ax = plt.subplots()
    for i_no in range(logits.shape[0]):
        
        # Features
        x = logits[i_no][0]
        y = logits[i_no][1]
        
        # Scatter based on feature 0 and feature 1
        if labels[i_no] == 0:
            #If label is 0 , then color by RED
            ax.scatter(x,y,c = 'red')
            ax.annotate(i_no,(x,y))
        else:
            #If label is 0 , then color by BLUE
            ax.scatter(x,y,c = 'blue')
            ax.annotate(i_no,(x,y))
    
    ax.set_title('epoch ' + str(title))
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    plt.show()

def evaluate(model, g, features, labels, mask,display = False):
    """
    Get accuracy of th model
    """
    #Evaluate Model
    model.eval()

    with th.no_grad():
        #Get features
        logits = model(g, features)
        #Predicted label
        logits = logits[mask]
        #Actual Lable
        labels = labels[mask]
        _, indices = th.max(logits, dim=1)
        if display != False:
            visualize_features(logits,labels,display)
        correct = th.sum(indices == labels)
        return correct.item() * 1.0 / len(labels)

"""# Training Model"""

#Load Model
net = Net()

#ADAM Optimizer
optimizer = th.optim.Adam(net.parameters(), lr = 2e-4)
dur = []

#Degrees in the karate graph
degrees = dgl_karate_graph.in_degrees(dgl_karate_graph.nodes())

#Number of Epochs
nfepochs = 300

for epoch in range(nfepochs):

    if epoch >=3:
        t0 = time.time()
    
    #Train model ON 
    net.train()
    
    # Get features
    logits = net(dgl_karate_graph, features)

    # Apply Softmax after the result
    logp = F.log_softmax(logits, 1)

    # Negative loss
    loss = F.nll_loss(logp[train_mask], labels[train_mask])

    # Backward
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if epoch >=3:
        dur.append(time.time() - t0)

    # Display the viaulaization of features  or NOT
    disp = False

    # For every fifth epoch draw the visualization
    if epoch % 50 == 0:
        disp = epoch

    #Test Accuracy
    acc = evaluate(net, dgl_karate_graph, features, labels, test_mask,disp)

    print("Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}".format(epoch, loss.item(), acc, np.mean(dur)))